{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_classfies_diseases.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "GfznmnZFF-3N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## イネの病気を判別するためのモデル(Model which clasifies the disease of rice plant)\n",
        "The model classfies the diseases of rice plant. Diseases includes \"rice blast\" and \"stripes\".\n",
        "When this program run, artificial intelligence classfies the disease in Flask that is right framework made by python.\n",
        "It depends on images that AI classfies diseases. So, if students would make the model, they must collect clear images about the diseases."
      ]
    },
    {
      "metadata": {
        "id": "Ci6syC_EFyN9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3  import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.optimizers import SGD\n",
        "from keras import optimizers\n",
        "from keras.regularizers import l2\n",
        "import matplotlib.image as mpimg\n",
        "from scipy.misc import imresize\n",
        "from keras.callbacks import EarlyStopping \n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hElT3d6NO8YP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c46bd95a-3990-4690-c3b5-c87464850666"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IzLpFL4kKYzD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "58416d78-114b-4c87-bf40-aeef85c41b31"
      },
      "cell_type": "code",
      "source": [
        "## Google Drive内のデータを確認\n",
        "!ls ./gdrive/'My Drive'/\"Colab Notebooks\""
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class.ipynb\t\t\triceplantordog.ipynb  ver\n",
            "model\t\t\t\ttrain (1)\t      verificate.ipynb\n",
            "model_classfies_diseases.ipynb\tUntitled0.ipynb\n",
            "rice-plant-man.ipynb\t\tvalidation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8xd8AGPkJFPg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## 多値分類のコードを追加していく\n",
        "\n",
        "### 元モデルをinceptionV3にセット\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "predictions = Dense(2, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADwo0T7YJc-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5949dea-885a-48eb-bc74-683213ae8661"
      },
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "\n",
        "### 学習用のデータをかさ増し\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = \"nearest\",\n",
        "    zoom_range = 0.3,\n",
        "    width_shift_range = 0.3,\n",
        "    height_shift_range=0.3,\n",
        "    rotation_range=90)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    './gdrive/My Drive/Colab Notebooks/train (1)',\n",
        "    target_size = (256, 256), ## デフォルト\n",
        "    batch_size = 32,\n",
        "    class_mode = \"categorical\") ## 多値分類なのでcategoricalに設定"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JrhZIC01QID6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4405e998-c229-419e-9a68-bbf84efc9f4b"
      },
      "cell_type": "code",
      "source": [
        "## 学習用データの水増し\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    './gdrive/My Drive/Colab Notebooks/validation/',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 42 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H34f7OMwsLiv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b49f3111-92dc-4ef9-cae9-83bdd65c156e"
      },
      "cell_type": "code",
      "source": [
        "print(train_generator.class_indices)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'imoti': 0, 'shima': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tWBpDd0OJwmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "8216b637-7265-467b-d0de-04a93b6042e2"
      },
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"./gdrive/My Drive/Colab Notebooks/saver/dis_{epoch:02d}.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "model.fit_generator(train_generator, \n",
        "                   steps_per_epoch=None, \n",
        "                   epochs=10, \n",
        "                   verbose=1, \n",
        "                   callbacks=None, \n",
        "                   validation_data=None, \n",
        "                   validation_steps=None, \n",
        "                   class_weight=None, \n",
        "                   max_queue_size=10, \n",
        "                   workers=1, \n",
        "                   use_multiprocessing=False, \n",
        "                   shuffle=True, \n",
        "                   initial_epoch=0)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 19s 5s/step - loss: 0.7042 - acc: 0.5272\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 3s 765ms/step - loss: 0.7382 - acc: 0.4975\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.7256 - acc: 0.4893\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 3s 797ms/step - loss: 0.7217 - acc: 0.4480\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.6909 - acc: 0.5165\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.7107 - acc: 0.4918\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.6701 - acc: 0.5603\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.6928 - acc: 0.5413\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 3s 731ms/step - loss: 0.6875 - acc: 0.5355\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.6696 - acc: 0.5495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8fbe86e0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    }
  ]
}